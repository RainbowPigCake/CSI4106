{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**CSI 4106 Introduction to Artificial Intelligence** <br/>\n",
        "*Assignment 1: Data Preparation*\n",
        "\n",
        "# Identification\n",
        "\n",
        "Name: Kaitlyn Wong<br/>\n",
        "Student Number: 300201087\n",
        "\n",
        "# Exploratory Analysis\n",
        "\n",
        "## Import important libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read Dataset\n",
        "\n",
        "As outlined in the project description, it should be possible for the correctors to ecute your notebook without requiring any downloads.\n",
        "\n",
        "To facilitate access to the dataset without the need for downloads, use the data ovided in the public GitHub repository and provide a link to the raw version of the taset.\n",
        "\n",
        "The link to the raw version is as follows:\n",
        "\n",
        "*https://raw.githubusercontent.com/GITHUB_USERNAME/REPOSITORY_NAME/main/DATASETNAME.v*\n",
        "\n",
        "For example:\n",
        "\n",
        "[https://github.com/turcotte/csi4106-f24/blob/main/assignments-data/a1/01/glass.csv]ttps://github.com/turcotte/csi4106-f24/blob/main/assignments-data/a1/01/glass.csv)\n",
        "\n",
        "Now provide the link to YOUR dataset and read the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Kaitlyn\\AppData\\Local\\Temp\\ipykernel_5564\\4171818970.py:24: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  credit_dataset = pd.read_csv(urls[\"credit\"])\n"
          ]
        }
      ],
      "source": [
        "urls = {\n",
        "    \"glass\": \"https://raw.githubusercontent.com/RainbowPigCake/CSI4106/refs/heads/main/datasets/01/glass.csv\",\n",
        "    \"dermatology\": \"https://raw.githubusercontent.com/RainbowPigCake/CSI4106/refs/heads/main/datasets/02/dermatology_database_1.csv\",\n",
        "    \"maternal\": \"https://raw.githubusercontent.com/RainbowPigCake/CSI4106/refs/heads/main/datasets/03/Maternal%20Health%20Risk%20Data%20Set.csv\",\n",
        "    \"car\": \"https://raw.githubusercontent.com/RainbowPigCake/CSI4106/refs/heads/main/datasets/04/car.data\",\n",
        "    \"wine\": \"https://raw.githubusercontent.com/RainbowPigCake/CSI4106/refs/heads/main/datasets/05/WineQT.csv\",\n",
        "    \"16personalities\": \"https://raw.githubusercontent.com/RainbowPigCake/CSI4106/refs/heads/main/datasets/06/16P.csv\",\n",
        "    \"credit\": \"https://raw.githubusercontent.com/RainbowPigCake/CSI4106/refs/heads/main/datasets/07/train.csv\"\n",
        "}\n",
        "\n",
        "glass_dataset = pd.read_csv(urls[\"glass\"])\n",
        "\n",
        "dermatology_dataset = pd.read_csv(urls[\"dermatology\"])\n",
        "\n",
        "maternal_dataset = pd.read_csv(urls[\"maternal\"])\n",
        "\n",
        "car_dataset = pd.read_csv(urls[\"car\"])\n",
        "\n",
        "wine_dataset = pd.read_csv(urls[\"wine\"])\n",
        "\n",
        "personalities_dataset = pd.read_csv(\n",
        "    urls[\"16personalities\"], encoding=\"ISO-8859-1\")\n",
        "\n",
        "credit_dataset = pd.read_csv(urls[\"credit\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Guidelines\n",
        "\n",
        "The following are the questions for Assignment 1. Under each question, we have provided an initial code cell. You are encouraged to add additional code cells to maintain logical separation of your code. For instance, place the definition of a function in one cell and its execution in a subsequent cell. This approach will help preserve clarity and enhance readability by avoiding the inclusion of excessive code within a single cell.\n",
        "\n",
        "1. **Analysis of Missing Values**: Examine the datasets to identify and assess ssing values in various attributes. Missing values may be represented by symbols ch as '?', empty strings, or other placeholders.\n",
        "\n",
        "    1.1 In the list of options, what are the datasets that contain missing values? ecifically, which attribute or attributes has missing values?\n",
        "        \n",
        "    1.2 Describe the methodology used for this investigation, and provide the rresponding code.\n",
        "\n",
        "    1.3 Data imputation involves replacing missing or incomplete data with substituted values to preserve the dataset's integrity for subsequent analysis. Propose imputation strategies for each attribute with missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For the glass dataset, there are 0 missing values in total\n",
            "\n",
            "For the dermatology dataset, there are 0 null values\n",
            "For the dermatology dataset, there are 8 question marks (the symbol that denotes a missing value)\n",
            "For the dermatology dataset, there are 8 missing values in total\n",
            "\n",
            "For the Maternal Health Risk dataset, there are 0 missing values in total\n",
            "\n",
            "For the car dataset, there are 0 missing values in total\n",
            "\n",
            "For the wine quality dataset, there are 0 missing values in total\n",
            "\n",
            "For the 16 personailities dataset, there are 0 missing values in total\n",
            "\n",
            "For the credit score dataset, there are 60071 null values\n",
            "For the credit score dataset, there are 29348 cells with the value '_' or '_______' as placeholders for missing values\n",
            "For the credit score dataset, there are 89419 missing values in total\n"
          ]
        }
      ],
      "source": [
        "#Count the number of null values for each dataset\n",
        "\n",
        "#According to kaggle, this dataset has no missing values\n",
        "glass_dataset_missing_values = glass_dataset.isnull().sum().sum()\n",
        "print(f\"For the glass dataset, there are {glass_dataset_missing_values} missing values in total\\n\")\n",
        "\n",
        "#According to kaggle, this dataset has 8 missing values in the age column, and they are denoted by a '?' symbol\n",
        "dermatology_dataset_missing_values = dermatology_dataset.isnull().sum().sum()\n",
        "print(f\"For the dermatology dataset, there are {dermatology_dataset_missing_values} null values\")\n",
        "dermatology_dataset_missing_values_question_marks = (dermatology_dataset == '?').sum().sum()\n",
        "print(f\"For the dermatology dataset, there are {dermatology_dataset_missing_values_question_marks} question marks (the symbol that denotes a missing value)\")\n",
        "print(f\"For the dermatology dataset, there are {dermatology_dataset_missing_values + dermatology_dataset_missing_values_question_marks} missing values in total\\n\")\n",
        "\n",
        "#According to kaggle, this dataset has no missing values\n",
        "maternal_dataset_missing_values = maternal_dataset.isnull().sum().sum()\n",
        "print(f\"For the Maternal Health Risk dataset, there are {maternal_dataset_missing_values} missing values in total\\n\")\n",
        "\n",
        "\n",
        "#According to kaggle, this dataset has no missing values\n",
        "car_dataset_missing_values = car_dataset.isnull().sum().sum()\n",
        "print(f\"For the car dataset, there are {car_dataset_missing_values} missing values in total\\n\")\n",
        "\n",
        "\n",
        "#Missing values are not specified explicitly on kaggle for this dataset\n",
        "wine_dataset_missing_values = wine_dataset.isnull().sum().sum()\n",
        "print(f\"For the wine quality dataset, there are {wine_dataset_missing_values} missing values in total\\n\")\n",
        "\n",
        "#Missing values are not specified explicitly on kaggle for this dataset\n",
        "personalities_dataset_missing_values = personalities_dataset.isnull().sum().sum()\n",
        "print(f\"For the 16 personailities dataset, there are {personalities_dataset_missing_values} missing values in total\\n\")\n",
        "\n",
        "\n",
        "#Kaggle doesn't specify whether there are missing values, but from looking at the dataset, I could see that some missing values were represented by 1 or many underscores\n",
        "credit_dataset_missing_values = credit_dataset.isnull().sum().sum()\n",
        "print(f\"For the credit score dataset, there are {credit_dataset_missing_values} null values\")\n",
        "credit_dataset_missing_values_underscore = (credit_dataset == '_').sum().sum()\n",
        "credit_dataset_missing_values_underscore += (credit_dataset == \"_______\").sum().sum()\n",
        "print(f\"For the credit score dataset, there are {credit_dataset_missing_values_underscore} cells with the value '_' or '_______' as placeholders for missing values\")\n",
        "print(f\"For the credit score dataset, there are {credit_dataset_missing_values + credit_dataset_missing_values_underscore} missing values in total\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The following column has missing values in the dermatology dataset\n",
            "age    8\n",
            "dtype: int64\n",
            "\n",
            "The following columns have missing values in the credit score dataset\n",
            "Name                        9985\n",
            "Occupation                  7062\n",
            "Monthly_Inhand_Salary      15002\n",
            "Type_of_Loan               11408\n",
            "Num_of_Delayed_Payment      7002\n",
            "Changed_Credit_Limit        2091\n",
            "Num_Credit_Inquiries        1965\n",
            "Credit_Mix                 20195\n",
            "Credit_History_Age          9030\n",
            "Amount_invested_monthly     4479\n",
            "Monthly_Balance             1200\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# The dermatology dataset and the credit score dataset are the only ones that have missing values, so we should see which columns\n",
        "#   the missing values come from in the datasets\n",
        "\n",
        "# for this dataset, the missing values only come from the question marks '?'\n",
        "series_derma = (dermatology_dataset == '?').sum()\n",
        "print(\"The following column has missing values in the dermatology dataset\")\n",
        "print(series_derma[series_derma != 0])\n",
        "print(\"\")\n",
        "# the age column is responsible for the missing values with '?' marks\n",
        "\n",
        "# for this dataset, the missing values come from empty values and underscores\n",
        "series_credit = credit_dataset.isnull().sum()\n",
        "series_credit = series_credit.add((credit_dataset == '_').sum())\n",
        "series_credit = series_credit.add((credit_dataset == \"_______\").sum())\n",
        "print(\"The following columns have missing values in the credit score dataset\")\n",
        "print(series_credit[series_credit != 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. **Select and familiarize yourself with a classification task:** Choose one of e provided datasets for further investigation. It is advisable to select a dataset ntaining a sufficiently large number of examples, ideally around 1,000, to ensure bust results when applying machine learning algorithms in the subsequent assignment.\n",
        "\n",
        "    2.1 What is the objective of the task? Is it intended for a specific plication? Do you possess expertise in this particular domain of application?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#I chose the 16 personalities dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. **Attribute Analysis**: \n",
        "\n",
        "    3.1 Determine which attributes lack informativeness and should be excluded to prove the effectiveness of the machine learning analysis. If all features are emed relevant, explicitly state this conclusion.\n",
        "\n",
        "    3.2 Examine the distribution of each attribute (column) within the dataset. Utilize histograms or boxplots to visualize the distributions, identifying any underlying patterns or outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. **Class Distribution Analysis**: Investigate the distribution of class labels within the dataset. Employ bar plots to visualize the frequency of instances for each class, and assess whether the dataset is balanced or imbalanced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. **Preprocessing**: \n",
        "\n",
        "    5.1 For numerical features, determine the best transformation to use. Indicate e transformation that seems appropriate and why. Include the code illustrating how  apply the transformation. For at least one attribute, show the distribution before d after the transformation. See [Preprocessing data](https://scikit-learn.org/able/modules/preprocessing.html).\n",
        "\n",
        "    5.2 For categorical features, show how to apply [one-hot encoding](https://ikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html).  your dataset does not have categorical data, show how to apply the one-hot encoder  the label (target variable)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. **Training and target data**: Set the Python variable `X` to designate the data and `y` to designate the target class. Make sure to select only the informative features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "7. **Training and test sets**: Split the dataset into training and testing sets. Reserve 20% of data for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--------------------------------------------------------------------------\n",
        "\n",
        "# References\n",
        "\n",
        "Make sure you provide references to ALL sources used (articles, code, algorithms).\n",
        "\n",
        "## AI transcript\n",
        "**Hint:** To share a link to your colab notebook, click on \"share\" on the top right. Then, under *General access* , change *Restricted* to \"Anyone with the link\"."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
